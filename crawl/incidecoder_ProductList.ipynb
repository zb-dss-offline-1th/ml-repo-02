{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성분 파일(csv) 불러오기\n",
    "ing_df = pd.read_csv('../data/ing_name.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성분 파일에서 'formatted_영문명' 컬럼만 웹페이지 접근용으로 사용\n",
    "# 결측값 제거 후 리스트로 변환\n",
    "ing_list = list(ing_df['formatted_영문명'].dropna())\n",
    "\n",
    "product_name = set() # 제품명\n",
    "product_label = set() # 제품명 (formatted - 웹페이지 접근용)\n",
    "search_failed = [] # 'formatted_영문명' 값으로 웹페이지 접근이 불가했던 건들 확인용도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성분으로 조회한 제품 리스트 만들기\n",
    "def add_ing_products(tags):  # html tag 를 받아와 조회하여 \n",
    "    for tag in tags:\n",
    "        if tag.text not in product_name: # 중복된 데이터는 추가하지 않도록, tag의 제품명이 product_name 셋에 없는 경우에만 추가\n",
    "            product_name.add(tag.text)\n",
    "            product_label.add(tag.attrs['data-ga-eventlabel'][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성분으로 접근한 웹페이지의 제품 리스트에 '다음페이지'가 존재하는지 확인하기 \n",
    "def next_page_exists(soup):\n",
    "    if \"Next\" in soup.find(id=\"product\").find_all(\"div\")[-1].text: # Next라는 문자가 해당 태그안에 존재하는지 여부 확인\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRAWLING - REMARK<br>\n",
    "성분페이지로 접근을 시도할 성분이 19417개이며, 개중 여러 제품에 공통적으로 들어가는 성분(예: water)의 경우 제품 페이지가 최대 1342페이지 까지 있음<br>\n",
    "&rarr; 데이터 수집에 상당한 시간이 소요 (24시간 이상 예상)\n",
    "\n",
    "아래 소스코드를 사용하되, 효율적인 수집을 위하여 다음과 같이 진행함:\n",
    "1. 성분리스트(ing_list)를 분할 (list slicing)<br> \n",
    "   &rarr; 다수의 컴퓨터에서 동시 수집하여 저장 후 병합\n",
    "\n",
    "2. 여러 제품에 공통적으로 들어가는 성분(water, glycerin)은 성분페이지 접근과정에서 제외<br>\n",
    "   (최종적으로 사용할 성분데이터는 InciDecoder 제품페이지에서 수집할 \"주성분 테이블\"의 데이터이기 때문)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ing in tqdm_notebook(ing_list): # 성분 리스트의 각 성분(formatted) 사용 \n",
    "    # 실제 수집시에는 슬라이싱으로 분할 수집 (예: ing_list[:2001],ing_list[2001:3001],...)\n",
    "    \n",
    "    url = 'https://incidecoder.com/ingredients/'+ ing # url 주소를 생성\n",
    "    \n",
    "    # if page exists (url로 접근 가능시)\n",
    "    try:\n",
    "        html = urlopen(url) \n",
    "        source = html.read()\n",
    "        soup = BeautifulSoup(source, \"html.parser\")\n",
    "        tags = soup.select(\"#product > div > a\") # html의 태그 불러오기  \n",
    "        add_ing_products(tags) # 태그에서 제품명 (일반+formatted) 리스트에 저장 - 중복건은 추가 x\n",
    "\n",
    "        if next_page_exists(soup): # 제품리스트가 1페이지 이상인지 확인\n",
    "            nextpage = True\n",
    "        \n",
    "        while nextpage: # 다음페이지가 존재하는 경우 반복 \n",
    "            nexturl = soup.find(id=\"product\").find_all(\"a\")[-1]['href'] # href태그로 다음페이지 url을 생성하여 해당 페이지 접근\n",
    "            url = 'https://incidecoder.com'+ nexturl \n",
    "            html = urlopen(url) \n",
    "            source = html.read()\n",
    "            soup = BeautifulSoup(source, \"html.parser\")\n",
    "            tags = soup.select(\"#product > div > a\")\n",
    "            add_ing_products(tags) # 다음페이지에서도 동일하게 제품명 받아와서 저장\n",
    "\n",
    "            if not next_page_exists(soup): # 더이상 다음 페이지가 없는 경우 while문 빠져나옴 \n",
    "                nextpage = False\n",
    "    \n",
    "    # if page does NOT exist (url로 접근 불가시 추후 확인 용도로 search_failed 리스트에 추가)\n",
    "    except Exception:\n",
    "        search_failed.append(ing)\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_all = pd.DataFrame(columns=['product_label'])\n",
    "product_all['product_label'] = list(product_label)\n",
    "product_all.to_csv('../data/product_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 수집 시에는 상기 REMARK에 명시한 바와 같이 분할 수집하여 아래 과정을 통해 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_list1 = pd.read_csv('product_list1.csv',index_col=False)\n",
    "# product_list2 = pd.read_csv('product_list2.csv',index_col=False)\n",
    "# product_list3 = pd.read_csv('product_list3.csv',index_col=False)\n",
    "# product_list4 = pd.read_csv('product_list4.csv',index_col=False)\n",
    "# product_list5 = pd.read_csv('product_list5.csv',index_col=False)\n",
    "# product_list6 = pd.read_csv('product_list6.csv',index_col=False)\n",
    "# product_list7 = pd.read_csv('product_list7.csv',index_col=False)\n",
    "# product_list8 = pd.read_csv('product_list8.csv',index_col=False)\n",
    "# product_list9 = pd.read_csv('product_list9.csv',index_col=False)\n",
    "\n",
    "# product_all = pd.concat([product_list1,product_list2,product_list3,product_list4,product_list5,product_list6,product_list7,product_list8,product_list9],ignore_index=True).drop_duplicates()\n",
    "# product_all['product_label'] = list(product_label)\n",
    "# product_all.to_csv('../data/product_list.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "189257d3ead7ed4cabfbed122a0ee4e0c566f64830e9ec3d7b4f7f74d108b2bc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ds_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
